<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Blur Interpolation Transformer for Real-World Motion from Blur.">
    <meta name="keywords" content="Blur Interpolation Transformer for Real-World Motion from Blur">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>BiT</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/zuica_icon.jpg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <link rel="stylesheet" href="./static/css/mycss.css">
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://zzh-tech.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
            </a>

            <div class="navbar-item has-dropdown is-hoverable">
                <a class="navbar-link">
                    More Research
                </a>
                <div class="navbar-dropdown">
                    <a class="navbar-item" href="https://zzh-tech.github.io/Animation-from-Blur/">
                        Animation-from-Blur
                    </a>
                </div>
            </div>
        </div>

    </div>
</nav>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Blur Interpolation Transformer for <br> Real-World Motion
                        from Blur</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zzh-tech.github.io/">Zhihang Zhong</a><sup>1,2</sup>,</span>
                        <span class="author-block">
              <a href="https://github.com/ljzycmd">Mingdeng Cao</a><sup>1</sup>,</span>
                        <span class="author-block">
              Xiang Ji<sup>1</sup>,</span>
                        <span class="author-block">
                        <a href="https://scholar.google.com/citations?user=JD-5DKcAAAAJ&hl=zh-CN">Yinqiang
                            Zheng</a><sup>1</sup>,
                        </span>
                        <span class="author-block">
              <a href="https://www.nii.ac.jp/en/faculty/digital_content/sato_imari/">Imari Sato</a><sup>1,2</sup>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>The University of Tokyo,</span>
                        <span class="author-block"><sup>2</sup>National Institute of Informatics</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                <a href="https://arxiv.org/abs/2211.11423"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <!--                            &lt;!&ndash; Video Link. &ndash;&gt;-->
                            <!--                            <span class="link-block">-->
                            <!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
                            <!--                   class="external-link button is-normal is-rounded is-dark">-->
                            <!--                  <span class="icon">-->
                            <!--                      <i class="fab fa-youtube"></i>-->
                            <!--                  </span>-->
                            <!--                  <span>Video</span>-->
                            <!--                </a>-->
                            <!--              </span>-->
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/zzh-tech/BiT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!--                            &lt;!&ndash; Dataset Link. &ndash;&gt;-->
                            <!--                            <span class="link-block">-->
                            <!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
                            <!--                   class="external-link button is-normal is-rounded is-dark">-->
                            <!--                  <span class="icon">-->
                            <!--                      <i class="far fa-images"></i>-->
                            <!--                  </span>-->
                            <!--                  <span>Data</span>-->
                            <!--                  </a>-->
                            <!--                                </span>-->

                            <div class="is-size-5 publication-authors">
                                <!--                        https://drive.google.com/file/d/1tlg7JHdTvZf6E6WjEg_SokiQf6BQTFRK/view?usp=sharing-->
                                <img src="https://drive.google.com/uc?export=view&id=1g0w0anEgafPJ4n1gXgn-o9Im7XnIzNvp"
                                     style="width: 38%;text-align: center">
                                <br>
                                <span style="color:black"><b>Accepted by CVPR'2023</b></span>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <!--            <video id="teaser" autoplay muted loop playsinline height="100%">-->
            <!--                <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/teaser.mp4"-->
            <!--                        type="video/mp4">-->
            <!--            </video>-->
            <img src="./arbitrary.png" alt="teaser">
            <h2 class="subtitle has-text-centered">
                <br>
                <b>
                    BiT (Blur Interpolation Transformer) is a fast and powerful transformer-based technique for
                    arbitrary factor blur interpolation with
                    state-of-the-art performance.
                </b>
            </h2>
        </div>
    </div>
</section>

<section class="hero is-light is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="subtitle has-text-centered">Synthetic Demos</h2>
            <div class="carousel results-carousel syn-demo">
                <div class="item1 item-1">
                    <!--                    https://drive.google.com/file/d/1MwPPZGuKXbdxHA_AzrgzVy6kHtXy23em/view?usp=sharing-->
                    <img src="https://drive.google.com/file/d/1noOH_zJgiDHQTq78evR2FD8sB3eISLyt/view?usp=sharing"
                         alt="demo1" class="item_img">
                </div>
                <div class="item1 item-2">
                    <!--                    https://drive.google.com/file/d/1N7UR_XfZocyvstsxq01HZxfpLHn76Qj_/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1ydFJfqhBpGiWnjm-xLRXiyjLl48fI1Wl"
                         alt="demo2">
                </div>
                <div class="item1 item-3">
                    <!--                    https://drive.google.com/file/d/1kHjIBdtcViRQMv2MQJI6q1uH3VVISNEk/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1xA3QRt_MF4Yipg0MpZMRH2p8xxF3UEkZ"
                         alt="demo3">
                </div>
                <div class="item1 item-4">
                    <!--                    https://drive.google.com/file/d/1U-NlJRfUbL8iDHvvgg4OiqaQC0RReNgY/view?usp=sharing-->
                    <img src="https://drive.google.com/file/d/1noOH_zJgiDHQTq78evR2FD8sB3eISLyt/view?usp=sharing"
                         alt="demo4">
                </div>
                <div class="item1 item-5">
                    <!--                    https://drive.google.com/file/d/19WR4MYfcb5N-2FJpsj1wefOlouUzjE6w/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1ydFJfqhBpGiWnjm-xLRXiyjLl48fI1Wl"
                         alt="demo5">
                </div>
                <div class="item1 item-6">
                    <!--                    https://drive.google.com/file/d/1hyd3pw4DZHH1OHPQ0UF1tAyohmXJsg7l/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1xA3QRt_MF4Yipg0MpZMRH2p8xxF3UEkZ"
                         alt="demo6">
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        This paper studies the challenging problem of recovering motion from blur, also known as joint
                        deblurring and interpolation or blur temporal super-resolution. The challenges are twofold: 1)
                        the current methods still leave considerable room for improvement in terms of visual quality
                        even on the synthetic dataset, and 2) poor generalization to real-world data. To this end, we
                        propose a blur interpolation transformer (BiT) to effectively unravel the underlying temporal
                        correlation encoded in blur. Based on multi-scale residual Swin transformer blocks, we introduce
                        dual-end temporal supervision and temporally symmetric ensembling strategies to generate
                        effective features for time-varying motion rendering. In addition, we design a hybrid camera
                        system to collect the first real-world dataset of one-to-many blur-sharp video pairs.
                        Experimental results show that BiT has a significant gain over the state-of-the-art methods on
                        the public dataset Adobe240. Besides, the proposed real-world dataset effectively helps the
                        model generalize well to real blurry scenarios.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!--        &lt;!&ndash; Paper video. &ndash;&gt;-->
        <!--        <div class="columns is-centered has-text-centered">-->
        <!--            <div class="column is-four-fifths">-->
        <!--                <h2 class="title is-3">Video</h2>-->
        <!--                <div class="publication-video">-->
        <!--                    &lt;!&ndash;                    https://drive.google.com/file/d/1TnRYTBv8EbnVJbsePyf2dyRuRqPhJ0it/view?usp=sharing&ndash;&gt;-->
        <!--                    <iframe src="https://drive.google.com/uc?export=view&id=1TnRYTBv8EbnVJbsePyf2dyRuRqPhJ0it"-->
        <!--                            allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
        <!--                </div>-->
        <!--            </div>-->
        <!--        </div>-->
        <!--/ Paper video. -->
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">

        <div class="columns is-centered">
            <!-- Visual Effects. &ndash;&gt;-->
            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Methodology</h2>
                    <p>
                        BiT is a a cutting-edge model or blur interpolation,
                        constructed using Multi-scale Residual Swin Transformer Blocks (MS-RSTBs). To enhance
                        the performance of BiT for blur interpolation, we have incorporated two temporal strategies,
                        namely Dual-end Temporal Supervision (DTS) and Temporally Symmetric Ensembling (TSE). DTS
                        involves the use of temporal supervision at both ends of the exposure time, while TSE involves
                        ensembling the features obtained from forward and backward directions of the same time point.
                        These strategies lead to a significant improvement in the performance of BiT for blur
                        interpolation.
                    </p>
                    <br>
                    <!--                    https://drive.google.com/file/d/1GYnSx79b6iDVkuZOpBfe1XfKY-Gp8ano/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1s-yKS17EPY7mr4GxiZqTeosxXGyLGAqz"
                         style="width: 90%;margin-left: auto;margin-right: auto;display: block">
                    <br>
                    <br>
                </div>
            </div>
        </div>

        <div class="columns is-centered">
            <!-- Visual Effects. &ndash;&gt;-->
            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Real-world Blur Interpolation Dataset (RBI)</h2>
                    <p>
                        The currently available synthetic dataset, such as Adobe240, exhibits unrealistic spikes or
                        steps in the blur trajectory. As a solution, we introduce the Real-World Blur Interpolation
                        (RBI) dataset, which is the first dataset of its kind, created using a custom hybrid camera
                        system. RBI offers a more authentic representation of real-world blur trajectories and is
                        designed specifically for blur interpolation tasks.
                    </p>
                    <br>
                    <img src="./dataset.png"
                         style="width: 90%;margin-left: auto;margin-right: auto;display: block">
                    <br>
                    <br>
                </div>
            </div>
        </div>

        <div class="columns is-centered">
            <!-- Visual Effects. &ndash;&gt;-->
            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Quantitative Results</h2>
                    <p>
                        Our method surpasses the prior art with a significant margin while also being much faster.
                    </p>
                    <!--                    https://drive.google.com/file/d/1uG5UwENqTeiqh6gqGT8gIauTf4f2nBFV/view?usp=sharing-->
                    <img src="https://drive.google.com/uc?export=view&id=1ndKOo9FoLDnkedxdVycuKP0Jbp8pj0xU"
                         style="width: 90%;margin-left: auto;margin-right: auto;display: block">
                    <br>
                    <br>
                </div>
            </div>
        </div>


        <div class=" columns is-centered">
            <!-- Visual Effects. &ndash;&gt;-->
            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Qualitative Results</h2>
                    <p>
                        We can see that the predictions of BiT and BiT++ are closer to the ground truth with clearer
                        details on both Adobe240 and RBI. Additionally, the optical flow of our results is also closer
                        to the groundtruth, which indicates better motion consistency.
                    </p>
                    <img src="https://drive.google.com/uc?export=view&id=17Sbnla_bFYcjs47czDKGoJwDI01OYKMU"
                         style="width: 90%;margin-left: auto;margin-right: auto;display: block">
                </div>
            </div>
        </div>

        <!--            &lt;!&ndash; Visual Effects. &ndash;&gt;-->
        <!--            <div class=" column">-->
        <!--                <div class="content">-->
        <!--                    <h2 class="title is-3">Visual Effects</h2>-->
        <!--                    <p>-->
        <!--                        Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect-->
        <!--                        would be impossible without nerfies since it would require going through a wall.-->
        <!--                    </p>-->
        <!--                    <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">-->
        <!--                        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"-->
        <!--                                type="video/mp4">-->
        <!--                    </video>-->
        <!--                </div>-->
        <!--            </div>-->
        <!--            &lt;!&ndash;/ Visual Effects. &ndash;&gt;-->

        <!--            &lt;!&ndash; Matting. &ndash;&gt;-->
        <!--            <div class="column">-->
        <!--                <h2 class="title is-3">Matting</h2>-->
        <!--                <div class="columns is-centered">-->
        <!--                    <div class="column content">-->
        <!--                        <p>-->
        <!--                            As a byproduct of our method, we can also solve the matting problem by ignoring-->
        <!--                            samples that fall outside of a bounding box during rendering.-->
        <!--                        </p>-->
        <!--                        <video id="matting-video" controls playsinline height="100%">-->
        <!--                            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"-->
        <!--                                    type="video/mp4">-->
        <!--                        </video>-->
        <!--                    </div>-->

        <!--                </div>-->
        <!--            </div>-->
        <!--        </div>-->
        <!--        &lt;!&ndash;/ Matting. &ndash;&gt;-->

        <!--        &lt;!&ndash; Animation. &ndash;&gt;-->
        <!--        <div class="columns is-centered">-->
        <!--            <div class="column is-full-width">-->
        <!--                <h2 class="title is-3">Animation</h2>-->

        <!--                &lt;!&ndash; Interpolating. &ndash;&gt;-->
        <!--                <h3 class="title is-4">Interpolating states</h3>-->
        <!--                <div class="content has-text-justified">-->
        <!--                    <p>-->
        <!--                        We can also animate the scene by interpolating the deformation latent codes of two input-->
        <!--                        frames. Use the slider here to linearly interpolate between the left frame and the right-->
        <!--                        frame.-->
        <!--                    </p>-->
        <!--                </div>-->
        <!--                <div class="columns is-vcentered interpolation-panel">-->
        <!--                    <div class="column is-3 has-text-centered">-->
        <!--                        <img src="https://homes.cs.washington.edu/~kpar/nerfies/images/interpolate_start.jpg"-->
        <!--                             class="interpolation-image"-->
        <!--                             alt="Interpolate start reference image."/>-->
        <!--                        <p>Start Frame</p>-->
        <!--                    </div>-->
        <!--                    <div class="column interpolation-video-column">-->
        <!--                        <div id="interpolation-image-wrapper">-->
        <!--                            Loading...-->
        <!--                        </div>-->
        <!--                        <input class="slider is-fullwidth is-large is-info"-->
        <!--                               id="interpolation-slider"-->
        <!--                               step="1" min="0" max="100" value="0" type="range">-->
        <!--                    </div>-->
        <!--                    <div class="column is-3 has-text-centered">-->
        <!--                        <img src="https://homes.cs.washington.edu/~kpar/nerfies/images/interpolate_end.jpg"-->
        <!--                             class="interpolation-image"-->
        <!--                             alt="Interpolation end reference image."/>-->
        <!--                        <p class="is-bold">End Frame</p>-->
        <!--                    </div>-->
        <!--                </div>-->
        <!--                <br/>-->
        <!--                &lt;!&ndash;/ Interpolating. &ndash;&gt;-->

        <!--                &lt;!&ndash; Re-rendering. &ndash;&gt;-->
        <!--                <h3 class="title is-4">Re-rendering the input video</h3>-->
        <!--                <div class="content has-text-justified">-->
        <!--                    <p>-->
        <!--                        Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel-->
        <!--                        viewpoint such as a stabilized camera by playing back the training deformations.-->
        <!--                    </p>-->
        <!--                </div>-->
        <!--                <div class="content has-text-centered">-->
        <!--                    <video id="replay-video"-->
        <!--                           controls-->
        <!--                           muted-->
        <!--                           preload-->
        <!--                           playsinline-->
        <!--                           width="75%">-->
        <!--                        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/replay.mp4"-->
        <!--                                type="video/mp4">-->
        <!--                    </video>-->
        <!--                </div>-->
        <!--                &lt;!&ndash;/ Re-rendering. &ndash;&gt;-->

        <!--            </div>-->
        <!--        </div>-->
        <!--        &lt;!&ndash;/ Animation. &ndash;&gt;-->


        <!-- Concurrent Work. -->
        <br>
        <br>
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Related Links</h2>

                <div class="content has-text-justified">
                    <p>
                        We have another interesting work that explicitly solves the directional
                        ambiguity problem in the
                        blur interpolation task:
                        <a href="https://arxiv.org/abs/2207.10123">Animation from Blur: Multi-modal
                            Blur Decomposition
                            with Motion Guidance</a> (<a
                            href="https://zzh-tech.github.io/Animation-from-Blur/">Website</a>,
                        <a href="https://github.com/zzh-tech/Animation-from-Blur">Code</a>).
                    </p>
                    <!--                    <p>-->
                    <!--                        <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a-->
                    <!--                            href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>-->
                    <!--                        both use deformation fields to model non-rigid scenes.-->
                    <!--                    </p>-->
                    <!--                    <p>-->
                    <!--                        Some works model videos with a NeRF by directly modulating the density, such as <a-->
                    <!--                            href="https://video-nerf.github.io/">Video-NeRF</a>, <a-->
                    <!--                            href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a-->
                    <!--                            href="https://neural-3d-video.github.io/">DyNeRF</a>-->
                    <!--                    </p>-->
                    <!--                    <p>-->
                    <!--                        There are probably many more by the time you are reading this. Check out <a-->
                    <!--                            href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>,-->
                    <!--                        and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF-->
                    <!--                        papers</a>.-->
                    <!--                    </p>-->
                </div>
            </div>
        </div>
        <!--/ Concurrent Work. -->
    </div>
</section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{zhong2023blur,
  title={Blur Interpolation Transformer for Real-World Motion from Blur},
  author={Zhong, Zhihang and Cao, Mingdeng and Ji, Xiang and Zheng, Yinqiang and Sato, Imari},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}</code></pre>
        <pre><code>@inproceedings{zhong2022animation,
  title={Animation from blur: Multi-modal blur decomposition with motion guidance},
  author={Zhong, Zhihang and Sun, Xiao and Wu, Zhirong and Zheng, Yinqiang and Lin, Stephen and Sato, Imari},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIX},
  pages={599--615},
  year={2022},
  organization={Springer}
}</code></pre>
        <pre><code>@article{zhong2022blur,
  title={Blur Interpolation Transformer for Real-World Motion from Blur},
  author={Zhong, Zhihang and Cao, Mingdeng and Ji, Xiang and Zheng, Yinqiang and Sato, Imari},
  journal={arXiv preprint arXiv:2211.11423},
  year={2022}
}</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <a class="icon-link"
               href="https://arxiv.org/abs/2211.11423">
                <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link" href="https://github.com/zzh-tech" class="external-link" disabled>
                <i class="fab fa-github"></i>
            </a>
        </div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a <a rel="license"
                                                            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        Website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
